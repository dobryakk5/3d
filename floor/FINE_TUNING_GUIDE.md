# üéì –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –¥–æ–æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ CubiCasa5K

## –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö CAD —á–µ—Ä—Ç–µ–∂–µ–π

### üìã –û–±—â–∏–π –ø–æ–¥—Ö–æ–¥: Transfer Learning (–ø–µ—Ä–µ–Ω–æ—Å –æ–±—É—á–µ–Ω–∏—è)

–ú–æ–¥–µ–ª—å —É–∂–µ —É–º–µ–µ—Ç:
- ‚úÖ –ù–∞—Ö–æ–¥–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤–∫—É
- ‚úÖ –ü–æ–Ω–∏–º–∞—Ç—å —á—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º–Ω–∞—Ç—ã
- ‚úÖ –†–∞–∑–ª–∏—á–∞—Ç—å —Å—Ç–µ–Ω—ã –∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ

–ù—É–∂–Ω–æ –Ω–∞—É—á–∏—Ç—å:
- üéØ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —à—Ç—Ä–∏—Ö–æ–≤–∫—É –∫–∞–∫ —Å—Ç–µ–Ω—ã
- üéØ –í–∏–¥–µ—Ç—å –¥—É–≥–∏ –∫–∞–∫ –¥–≤–µ—Ä–∏
- üéØ –ù–∞—Ö–æ–¥–∏—Ç—å –æ–∫–Ω–∞ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –º–µ—Ç–∫–∞–º

---

## üéØ –ü–ª–∞–Ω –¥–æ–æ–±—É—á–µ–Ω–∏—è (–æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∫ —Å–ª–æ–∂–Ω–æ–º—É)

### –≠—Ç–∞–ø 1: –°—Ç–µ–Ω—ã (–°–ê–ú–û–ï –ü–†–û–°–¢–û–ï - –Ω–∞—á–Ω—ë–º —Å —ç—Ç–æ–≥–æ) ‚≠ê

**–ü–æ—á–µ–º—É –Ω–∞—á–∏–Ω–∞–µ–º —Å–æ —Å—Ç–µ–Ω:**
- ‚úÖ –°–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞
- ‚úÖ –ë–æ–ª—å—à–µ –≤—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø–ª–∞–Ω–µ
- ‚úÖ –ß–µ—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã
- ‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é —Å—Ç–µ–Ω

**–ß—Ç–æ –Ω—É–∂–Ω–æ:**

1. **–°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ: 50-100 –ø–ª–∞–Ω–æ–≤**
   ```
   plan_floor1.jpg    ‚Üí wall_mask_1.png
   plan_floor2.jpg    ‚Üí wall_mask_2.png
   plan_floor3.jpg    ‚Üí wall_mask_3.png
   ...
   ```

2. **–†–∞–∑–º–µ—Ç–∏—Ç—å —Å—Ç–µ–Ω—ã** (—Å–æ–∑–¥–∞—Ç—å –º–∞—Å–∫–∏):
   - –ë–µ–ª—ã–π —Ü–≤–µ—Ç (255) = —Å—Ç–µ–Ω–∞
   - –ß–µ—Ä–Ω—ã–π —Ü–≤–µ—Ç (0) = –Ω–µ —Å—Ç–µ–Ω–∞
   - –§–æ—Ä–º–∞—Ç: PNG, —Ä–∞–∑–º–µ—Ä –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª

3. **–î–æ–æ–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–π —Å—Ç–µ–Ω**:
   - –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏ –º–æ–¥–µ–ª–∏
   - –û–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥ –¥–ª—è –∫–ª–∞—Å—Å–∞ "Wall"
   - 10-20 —ç–ø–æ—Ö

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 85-90% —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Å—Ç–µ–Ω–∞—Ö

---

### –≠—Ç–∞–ø 2: –î–≤–µ—Ä–∏ (–°–†–ï–î–ù–Ø–Ø –°–õ–û–ñ–ù–û–°–¢–¨)

**–ü–æ—á–µ–º—É –¥–≤–µ—Ä–∏ –≤—Ç–æ—Ä—ã–µ:**
- ‚úÖ –ß–µ—Ç–∫–∏–µ —Å–∏–º–≤–æ–ª—ã (–¥—É–≥–∏)
- ‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –ø–ª–∞–Ω–µ
- ‚ö†Ô∏è –ù—É–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥—É–≥—É + —Ç–µ–∫—Å—Ç

**–ü–æ–¥—Ö–æ–¥ 1: –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥—É–≥–∞—Ö (–ø—Ä–æ—â–µ)**

1. **–°–æ–±—Ä–∞—Ç—å 30-50 –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–≤–µ—Ä–µ–π**
   ```
   door_001.jpg ‚Üí door_mask_001.png
   door_002.jpg ‚Üí door_mask_002.png
   ```

2. **–†–∞–∑–º–µ—Ç–∫–∞:**
   - –í—ã—Ä–µ–∑–∞—Ç—å –æ–±–ª–∞—Å—Ç–∏ —Å –¥–≤–µ—Ä—è–º–∏ (128x128px)
   - –û—Ç–º–µ—Ç–∏—Ç—å –≥–¥–µ –¥–≤–µ—Ä—å (–±–µ–ª—ã–π), –≥–¥–µ –Ω–µ—Ç (—á–µ—Ä–Ω—ã–π)
   - –í–∫–ª—é—á–∏—Ç—å –¥—É–≥—É –≤ —Ä–∞–∑–º–µ—Ç–∫—É

3. **–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è:**
   - –ü–æ–≤–æ—Ä–æ—Ç—ã (0¬∞, 90¬∞, 180¬∞, 270¬∞)
   - –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (0.8x - 1.2x)
   - –ü–æ–ª—É—á–∞–µ–º 200-300 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ 50

**–ü–æ–¥—Ö–æ–¥ 2: Hybrid —Å OCR (—Ç–æ—á–Ω–µ–µ)**

1. **–î–µ—Ç–µ–∫—Ü–∏—è –¥—É–≥ —á–µ—Ä–µ–∑ Computer Vision**
   - –ò—Å–ø–æ–ª—å–∑—É–µ–º HoughCircles (—É–∂–µ –µ—Å—Ç—å –≤ –∫–æ–¥–µ)

2. **–ù–∞—Ö–æ–¥–∏–º —Ç–µ–∫—Å—Ç –î–í-***
   - Tesseract OCR –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
   - –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "–î–í-\d+"

3. **–°–≤—è–∑—ã–≤–∞–µ–º –¥—É–≥—É —Å —Ç–µ–∫—Å—Ç–æ–º**
   - –ë–ª–∏–∂–∞–π—à–∞—è –¥—É–≥–∞ –∫ —Ç–µ–∫—Å—Ç—É = –¥–≤–µ—Ä—å

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 70-80% —Ç–æ—á–Ω–æ—Å—Ç—å

---

### –≠—Ç–∞–ø 3: –û–∫–Ω–∞ (–°–ê–ú–û–ï –°–õ–û–ñ–ù–û–ï)

**–ü–æ—á–µ–º—É –æ–∫–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ:**
- ‚ö†Ô∏è –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ (–û–ö-*, –î–ù-*)
- ‚ö†Ô∏è –ù–µ—Ç —á–µ—Ç–∫–æ–≥–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
- ‚ö†Ô∏è –ù—É–∂–µ–Ω OCR + –∫–æ–Ω—Ç–µ–∫—Å—Ç

**–ü–æ–¥—Ö–æ–¥: OCR + –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å**

1. **–ù–∞—Ö–æ–¥–∏–º —Ç–µ–∫—Å—Ç OCR**
   ```python
   import pytesseract

   # –ö–æ–Ω—Ñ–∏–≥ –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
   config = '--oem 3 --psm 6 -l rus'
   text = pytesseract.image_to_data(image, config=config, output_type=Output.DICT)

   # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –û–ö-*, –î–ù-*
   for i, word in enumerate(text['text']):
       if '–û–ö' in word or '–î–ù' in word:
           x, y, w, h = text['left'][i], text['top'][i], text['width'][i], text['height'][i]
           # –≠—Ç–æ –æ–∫–Ω–æ!
   ```

2. **–°–º–æ—Ç—Ä–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç:**
   - –û–∫–Ω–æ –æ–±—ã—á–Ω–æ –Ω–∞ –≤–Ω–µ—à–Ω–µ–π —Å—Ç–µ–Ω–µ
   - –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–µ–Ω—É —Ä—è–¥–æ–º —Å —Ç–µ–∫—Å—Ç–æ–º
   - –ï—Å–ª–∏ —Å—Ç–µ–Ω–∞ –≤–Ω–µ—à–Ω—è—è ‚Üí –æ–∫–Ω–æ

3. **–°–æ–∑–¥–∞—ë–º –º–∞—Å–∫—É –æ–∫–æ–Ω**

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 60-70% —Ç–æ—á–Ω–æ—Å—Ç—å

---

## üíª –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (–≠—Ç–∞–ø 1: –°—Ç–µ–Ω—ã)

### –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Ä–∞–∑–º–µ—Ç–∫–∏

–Ø —Å–æ–∑–¥–∞–º –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ —Å—Ç–µ–Ω:

```python
# annotate_walls.py
import cv2
import numpy as np
from pathlib import Path

class WallAnnotator:
    def __init__(self, image_path):
        self.image = cv2.imread(image_path)
        self.mask = np.zeros(self.image.shape[:2], dtype=np.uint8)
        self.drawing = False
        self.brush_size = 10

    def draw(self, event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
        elif event == cv2.EVENT_MOUSEMOVE:
            if self.drawing:
                cv2.circle(self.mask, (x, y), self.brush_size, 255, -1)
        elif event == cv2.EVENT_LBUTTONUP:
            self.drawing = False

    def annotate(self):
        cv2.namedWindow('Annotate Walls')
        cv2.setMouseCallback('Annotate Walls', self.draw)

        while True:
            # Overlay mask on image
            overlay = self.image.copy()
            overlay[self.mask > 0] = [0, 255, 0]  # Green for walls
            display = cv2.addWeighted(self.image, 0.7, overlay, 0.3, 0)

            cv2.imshow('Annotate Walls', display)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('s'):  # Save
                return self.mask
            elif key == ord('q'):  # Quit
                return None
            elif key == ord('+'):  # Increase brush
                self.brush_size += 2
            elif key == ord('-'):  # Decrease brush
                self.brush_size = max(2, self.brush_size - 2)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
annotator = WallAnnotator('plan_floor1.jpg')
mask = annotator.annotate()
if mask is not None:
    cv2.imwrite('wall_mask_1.png', mask)
```

### –®–∞–≥ 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ (Semi-supervised)

–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä–≤–∏—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏:

```python
# auto_annotate.py
import torch
import numpy as np
from PIL import Image

def auto_annotate_walls(image_path, model):
    """–°–æ–∑–¥–∞—ë—Ç –ø–µ—Ä–≤–∏—á–Ω—É—é —Ä–∞–∑–º–µ—Ç–∫—É, –∫–æ—Ç–æ—Ä—É—é –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å –≤—Ä—É—á–Ω—É—é"""

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = Image.open(image_path).convert('RGB')
    img_np = np.array(img).astype(np.float32) / 255.0
    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0)

    # –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        pred = model(img_tensor)

    # –ò–∑–≤–ª–µ—á—å —Å—Ç–µ–Ω—ã (–∫–ª–∞—Å—Å 2)
    rooms_logits = pred[0, 21:33]
    rooms_pred = torch.softmax(rooms_logits, 0)
    wall_prob = rooms_pred[2].cpu().numpy()

    # –ü–æ—Ä–æ–≥
    wall_mask = (wall_prob > 0.5).astype(np.uint8) * 255

    return wall_mask

# –°–æ–∑–¥–∞—ë–º —Ä–∞–∑–º–µ—Ç–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –ø–æ—Ç–æ–º —É—Ç–æ—á–Ω—è–µ–º –≤—Ä—É—á–Ω—É—é
mask = auto_annotate_walls('plan_floor1.jpg', model)
Image.fromarray(mask).save('wall_mask_1_auto.png')
```

### –®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```python
# prepare_dataset.py
import os
from pathlib import Path
import json

def prepare_training_data(data_dir='training_data'):
    """
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
    training_data/
        images/
            plan_001.jpg
            plan_002.jpg
            ...
        masks/
            walls/
                plan_001.png
                plan_002.png
            doors/
                plan_001.png
                plan_002.png
    """

    dataset = {
        'images': [],
        'masks': []
    }

    images_dir = Path(data_dir) / 'images'
    masks_dir = Path(data_dir) / 'masks' / 'walls'

    for img_path in sorted(images_dir.glob('*.jpg')):
        mask_path = masks_dir / f"{img_path.stem}.png"

        if mask_path.exists():
            dataset['images'].append(str(img_path))
            dataset['masks'].append(str(mask_path))

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫
    with open(f'{data_dir}/dataset.json', 'w') as f:
        json.dump(dataset, f, indent=2)

    print(f"Prepared {len(dataset['images'])} training samples")

    return dataset
```

### –®–∞–≥ 4: –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```python
# fine_tune_walls.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np
import json

class WallDataset(Dataset):
    def __init__(self, json_path, transform=None):
        with open(json_path, 'r') as f:
            self.data = json.load(f)
        self.transform = transform

    def __len__(self):
        return len(self.data['images'])

    def __getitem__(self, idx):
        # Load image
        img = Image.open(self.data['images'][idx]).convert('RGB')
        img = np.array(img, dtype=np.float32) / 255.0
        img = (img - 0.5) * 2  # Normalize
        img = torch.from_numpy(img).permute(2, 0, 1)

        # Load mask
        mask = Image.open(self.data['masks'][idx]).convert('L')
        mask = np.array(mask, dtype=np.float32) / 255.0
        mask = torch.from_numpy(mask).unsqueeze(0)

        return img, mask

def fine_tune_wall_detection(model, dataset_path, epochs=20, lr=1e-4):
    """
    –î–æ–æ–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∞ —Å—Ç–µ–Ω
    """

    # –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤—Å–µ –≤–µ—Å–∞ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
    for param in model.parameters():
        param.requires_grad = False

    # –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥ –¥–ª—è —Å—Ç–µ–Ω (–∫–∞–Ω–∞–ª—ã 21-23)
    # –≠—Ç–æ room segmentation —Å–ª–æ–∏
    model.conv4_.weight.requires_grad = True
    model.conv4_.bias.requires_grad = True
    model.upsample.weight.requires_grad = True
    model.upsample.bias.requires_grad = True

    # –î–∞—Ç–∞—Å–µ—Ç
    dataset = WallDataset(dataset_path)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä - —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–∑–º–æ—Ä–æ–∂–∂–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤
    optimizer = optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=lr
    )

    # Loss function
    criterion = nn.BCEWithLogitsLoss()

    model.cuda()
    model.train()

    for epoch in range(epochs):
        total_loss = 0

        for images, masks in dataloader:
            images = images.cuda()
            masks = masks.cuda()

            # Forward
            outputs = model(images)

            # –ò–∑–≤–ª–µ—á—å —Å—Ç–µ–Ω—ã (–∫–ª–∞—Å—Å 2 –≤ room segmentation)
            wall_logits = outputs[:, 23:24, :, :]  # –ö–∞–Ω–∞–ª —Å—Ç–µ–Ω

            # Loss
            loss = criterion(wall_logits, masks)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
        if (epoch + 1) % 5 == 0:
            torch.save({
                'epoch': epoch,
                'model_state': model.state_dict(),
                'optimizer_state': optimizer.state_dict(),
                'loss': avg_loss
            }, f'finetuned_walls_epoch_{epoch+1}.pkl')

    print("Fine-tuning complete!")
    return model

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
from floortrans.models import get_model

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
model = get_model('hg_furukawa_original', 51)
model.conv4_ = torch.nn.Conv2d(256, 44, bias=True, kernel_size=1)
model.upsample = torch.nn.ConvTranspose2d(44, 44, kernel_size=4, stride=4)

checkpoint = torch.load('model_best_val_loss_var.pkl')
model.load_state_dict(checkpoint['model_state'])

# –î–æ–æ–±—É—á–∏—Ç—å
model = fine_tune_wall_detection(
    model,
    'training_data/dataset.json',
    epochs=20,
    lr=1e-4
)

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
torch.save({
    'model_state': model.state_dict(),
}, 'model_finetuned_walls.pkl')
```

---

## üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–Ω–Ω—ã–º

### –î–ª—è —Å—Ç–µ–Ω:
- **–ú–∏–Ω–∏–º—É–º:** 30 –ø–ª–∞–Ω–æ–≤
- **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** 100 –ø–ª–∞–Ω–æ–≤
- **–í—Ä–µ–º—è —Ä–∞–∑–º–µ—Ç–∫–∏:** ~5-10 –º–∏–Ω—É—Ç –Ω–∞ –ø–ª–∞–Ω
- **–ò—Ç–æ–≥–æ:** 5-16 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã

### –î–ª—è –¥–≤–µ—Ä–µ–π:
- **–ú–∏–Ω–∏–º—É–º:** 20 –ø–ª–∞–Ω–æ–≤ (100+ –¥–≤–µ—Ä–µ–π)
- **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ:** 50 –ø–ª–∞–Ω–æ–≤ (250+ –¥–≤–µ—Ä–µ–π)
- **–í—Ä–µ–º—è:** ~10 –º–∏–Ω—É—Ç –Ω–∞ –ø–ª–∞–Ω
- **–ò—Ç–æ–≥–æ:** 3-8 —á–∞—Å–æ–≤

### –î–ª—è –æ–∫–æ–Ω:
- **–ú–∏–Ω–∏–º—É–º:** 20 –ø–ª–∞–Ω–æ–≤ (100+ –æ–∫–æ–Ω)
- **OCR –ø–æ–¥—Ö–æ–¥:** –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏
- **–í—Ä–µ–º—è:** –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ OCR ~2 —á–∞—Å–∞

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä)

–ï—Å–ª–∏ –≤—Ä–µ–º–µ–Ω–∏ –º–∞–ª–æ, –≤–æ—Ç –º–∏–Ω–∏–º—É–º –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:

1. **10 –ø–ª–∞–Ω–æ–≤** –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ –≤–∞—à
2. **–†–∞–∑–º–µ—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å—Ç–µ–Ω—ã** (—Å–∞–º–æ–µ –ø—Ä–æ—Å—Ç–æ–µ)
3. **–î–æ–æ–±—É—á–∏—Ç—å 10 —ç–ø–æ—Ö** (~1 —á–∞—Å –Ω–∞ GPU)
4. **–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å**

–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: +20-30% —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ —Å—Ç–µ–Ω–∞—Ö

---

## üõ†Ô∏è –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SAM (Segment Anything)

–ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –æ—Ç Meta - –º–æ–∂–Ω–æ —Ä–∞–∑–º–µ—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ:

```python
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator

# –ó–∞–≥—Ä—É–∑–∏—Ç—å SAM
sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h.pth")

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
mask_generator = SamAutomaticMaskGenerator(sam)
masks = mask_generator.generate(image)

# –í—ã–±—Ä–∞—Ç—å –º–∞—Å–∫–∏ —Å—Ç–µ–Ω –≤—Ä—É—á–Ω—É—é (–∫–ª–∏–∫–Ω—É–≤ –Ω–∞ –Ω–∏—Ö)
# –ù–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ —á–µ–º —Ä–∏—Å–æ–≤–∞—Ç—å!
```

---

## ‚ùì –ß—Ç–æ –ª—É—á—à–µ –¥–ª—è –≤–∞—Å?

### –í–∞—Ä–∏–∞–Ω—Ç A: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —É—Å–∏–ª–∏—è (OCR-based)
‚úÖ –í—Ä–µ–º—è: 1 –¥–µ–Ω—å
‚úÖ –î–∞–Ω–Ω—ã–µ: 0 —Ä–∞–∑–º–µ—Ç–∫–∏
‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: 50-60% —Ç–æ—á–Ω–æ—Å—Ç—å
- –¢–æ–ª—å–∫–æ OCR –¥–ª—è –¥–≤–µ—Ä–µ–π (–î–í-*) –∏ –æ–∫–æ–Ω (–û–ö-*)
- –î—É–≥–∏ —á–µ—Ä–µ–∑ HoughCircles

### –í–∞—Ä–∏–∞–Ω—Ç B: –°—Ä–µ–¥–Ω–∏–µ —É—Å–∏–ª–∏—è (Hybrid)
‚úÖ –í—Ä–µ–º—è: 1 –Ω–µ–¥–µ–ª—è
‚úÖ –î–∞–Ω–Ω—ã–µ: 30 –ø–ª–∞–Ω–æ–≤
‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: 70-80% —Ç–æ—á–Ω–æ—Å—Ç—å
- –î–æ–æ–±—É—á–∏—Ç—å —Å—Ç–µ–Ω—ã
- OCR + CV –¥–ª—è –¥–≤–µ—Ä–µ–π/–æ–∫–æ–Ω

### –í–∞—Ä–∏–∞–Ω—Ç C: –ú–∞–∫—Å–∏–º—É–º –∫–∞—á–µ—Å—Ç–≤–∞ (Full fine-tuning)
‚úÖ –í—Ä–µ–º—è: 2-3 –Ω–µ–¥–µ–ª–∏
‚úÖ –î–∞–Ω–Ω—ã–µ: 100 –ø–ª–∞–Ω–æ–≤
‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: 85-90% —Ç–æ—á–Ω–æ—Å—Ç—å
- –î–æ–æ–±—É—á–∏—Ç—å –≤—Å–µ –∫–ª–∞—Å—Å—ã
- –ë–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç

---

## üìù –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ß—Ç–æ —Ö–æ—Ç–∏—Ç–µ –¥–µ–ª–∞—Ç—å?

1. **–ù–∞—á–∞—Ç—å —Å —Ä–∞–∑–º–µ—Ç–∫–∏ —Å—Ç–µ–Ω** - —è —Å–æ–∑–¥–∞–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç?
2. **–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å OCR –ø–æ–¥—Ö–æ–¥** –¥–ª—è –¥–≤–µ—Ä–µ–π/–æ–∫–æ–Ω –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏?
3. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SAM** –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏?
4. **Hybrid –ø–æ–¥—Ö–æ–¥** - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—Å–µ–≥–æ?

–ù–∞–ø–∏—à–∏—Ç–µ –∫–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤–∞–º –±–ª–∏–∂–µ, –∏ —è —Å–æ–∑–¥–∞–º –≥–æ—Ç–æ–≤—ã–π –∫–æ–¥!
