#!/usr/bin/env python
"""
Automatic wall detection by finding hatching patterns
Finds diagonal lines (—à—Ç—Ä–∏—Ö–æ–≤–∫–∞) and marks them as walls
"""
import cv2
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from PIL import Image
from scipy import ndimage
import json

def detect_hatching_patterns(image_np, visualize=False):
    """
    –û–±–Ω–∞—Ä—É–∂–∏—Ç—å —à—Ç—Ä–∏—Ö–æ–≤–∫—É –Ω–∞ —á–µ—Ä—Ç–µ–∂–µ

    –®—Ç—Ä–∏—Ö–æ–≤–∫–∞ = –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
    """
    print("\n[1/6] Converting to grayscale and preprocessing...")
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)

    # –£–ª—É—á—à–∏—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)

    # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
    _, binary = cv2.threshold(enhanced, 200, 255, cv2.THRESH_BINARY_INV)

    if visualize:
        cv2.imwrite('debug_1_binary.png', binary)

    print("[2/6] Detecting line patterns...")

    # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏–Ω–∏–π —Ä–∞–∑–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    # –®—Ç—Ä–∏—Ö–æ–≤–∫–∞ –æ–±—ã—á–Ω–æ –ø–æ–¥ —É–≥–ª–æ–º 45¬∞ –∏–ª–∏ -45¬∞
    hatching_masks = []

    # –£–≥–ª—ã —à—Ç—Ä–∏—Ö–æ–≤–∫–∏ (–≤ –≥—Ä–∞–¥—É—Å–∞—Ö)
    angles = [45, -45, 135, -135]  # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è —à—Ç—Ä–∏—Ö–æ–≤–∫–∞

    for angle in angles:
        print(f"   Checking {angle}¬∞ lines...")

        # –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–ª—è –ª–∏–Ω–∏–π –ø–æ–¥ —É–≥–ª–æ–º
        length = 15  # –î–ª–∏–Ω–∞ –ª–∏–Ω–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        kernel = create_line_kernel(length, angle)

        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è - –Ω–∞–π—Ç–∏ –ª–∏–Ω–∏–∏
        detected = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)

        if visualize:
            cv2.imwrite(f'debug_2_lines_{angle}.png', detected)

        hatching_masks.append(detected)

    # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    hatching_combined = np.zeros_like(binary)
    for mask in hatching_masks:
        hatching_combined = cv2.bitwise_or(hatching_combined, mask)

    if visualize:
        cv2.imwrite('debug_3_hatching_combined.png', hatching_combined)

    print("[3/6] Finding hatching regions...")

    # –ù–∞–π—Ç–∏ –æ–±–ª–∞—Å—Ç–∏ —Å –ø–ª–æ—Ç–Ω–æ–π —à—Ç—Ä–∏—Ö–æ–≤–∫–æ–π
    # –®—Ç—Ä–∏—Ö–æ–≤–∫–∞ = –º–Ω–æ–≥–æ –ª–∏–Ω–∏–π –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
    kernel_dilate = np.ones((5, 5), np.uint8)
    hatching_dilated = cv2.dilate(hatching_combined, kernel_dilate, iterations=2)

    # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —à—Ç—Ä–∏—Ö–æ–≤–∫–∏
    kernel_density = np.ones((20, 20), np.uint8)
    density = cv2.filter2D(hatching_dilated.astype(np.float32), -1, kernel_density)

    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
    density = (density / density.max() * 255).astype(np.uint8)

    if visualize:
        cv2.imwrite('debug_4_density.png', density)

    # –ü–æ—Ä–æ–≥ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ - –≥–¥–µ –º–Ω–æ–≥–æ –ª–∏–Ω–∏–π = —Å—Ç–µ–Ω–∞
    threshold = 30  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —à—Ç—Ä–∏—Ö–æ–≤–∫–∏
    wall_mask = (density > threshold).astype(np.uint8) * 255

    print("[4/6] Refining wall boundaries...")

    # –£–±—Ä–∞—Ç—å —à—É–º
    kernel_close = np.ones((7, 7), np.uint8)
    wall_mask = cv2.morphologyEx(wall_mask, cv2.MORPH_CLOSE, kernel_close)

    # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –¥—ã—Ä—ã
    kernel_fill = np.ones((15, 15), np.uint8)
    wall_mask = cv2.morphologyEx(wall_mask, cv2.MORPH_CLOSE, kernel_fill)

    if visualize:
        cv2.imwrite('debug_5_walls_refined.png', wall_mask)

    return wall_mask, hatching_combined, density

def create_line_kernel(length, angle_deg):
    """–°–æ–∑–¥–∞—Ç—å kernel –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏–Ω–∏–π –ø–æ–¥ —É–≥–ª–æ–º"""
    angle_rad = np.deg2rad(angle_deg)

    # –°–æ–∑–¥–∞—Ç—å –ª–∏–Ω–∏—é
    kernel = np.zeros((length, length), dtype=np.uint8)
    center = length // 2

    # –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å –ª–∏–Ω–∏—é –ø–æ–¥ —É–≥–ª–æ–º
    for i in range(length):
        offset = i - center
        x = int(center + offset * np.cos(angle_rad))
        y = int(center + offset * np.sin(angle_rad))

        if 0 <= x < length and 0 <= y < length:
            kernel[y, x] = 1

    return kernel

def detect_hatching_by_frequency(image_np):
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥: –∞–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç
    –®—Ç—Ä–∏—Ö–æ–≤–∫–∞ —Å–æ–∑–¥–∞–µ—Ç —Ä–µ–≥—É–ª—è—Ä–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω —á–∞—Å—Ç–æ—Ç
    """
    print("\n[ALT] Using frequency analysis...")
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)

    # FFT –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    f_transform = np.fft.fft2(gray)
    f_shift = np.fft.fftshift(f_transform)
    magnitude = np.abs(f_shift)

    # –ù–∞–π—Ç–∏ –ø–∏–∫–∏ —á–∞—Å—Ç–æ—Ç (—Ä–µ–≥—É–ª—è—Ä–Ω–∞—è —à—Ç—Ä–∏—Ö–æ–≤–∫–∞ –¥–∞—ë—Ç –ø–∏–∫–∏)
    # –≠—Ç–æ –ø–æ–∫–∞–∂–µ—Ç –≥–¥–µ –µ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ª–∏–Ω–∏–∏

    return magnitude

def extract_wall_contours(wall_mask):
    """–ò–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç—É—Ä—ã —Å—Ç–µ–Ω"""
    contours, hierarchy = cv2.findContours(
        wall_mask,
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )

    # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É
    wall_contours = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 100:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å —Å—Ç–µ–Ω—ã
            wall_contours.append(contour)

    return wall_contours

def analyze_walls(wall_mask, scale_factor=1.0):
    """–ê–Ω–∞–ª–∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å—Ç–µ–Ω"""
    # –ü–æ–¥—Å—á–µ—Ç –ø–∏–∫—Å–µ–ª–µ–π —Å—Ç–µ–Ω
    wall_pixels = np.sum(wall_mask > 0)
    total_pixels = wall_mask.size
    coverage = wall_pixels / total_pixels * 100

    # –°–∫–µ–ª–µ—Ç–æ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã
    from skimage.morphology import skeletonize
    skeleton = skeletonize(wall_mask > 0)
    wall_length = np.sum(skeleton)

    # –°—Ä–µ–¥–Ω—è—è —Ç–æ–ª—â–∏–Ω–∞
    avg_thickness = wall_pixels / wall_length if wall_length > 0 else 0

    # –ö–æ–Ω—Ç—É—Ä—ã
    contours = extract_wall_contours(wall_mask)

    stats = {
        'wall_pixels': int(wall_pixels),
        'coverage_percent': float(coverage),
        'estimated_length_px': int(wall_length * scale_factor),
        'average_thickness_px': int(avg_thickness * scale_factor),
        'num_segments': len(contours),
        'wall_area_px2': int(wall_pixels * scale_factor * scale_factor)
    }

    return stats

def main():
    print("=" * 80)
    print("AUTOMATIC WALL DETECTION BY HATCHING PATTERN RECOGNITION")
    print("=" * 80)

    image_path = 'plan_floor1.jpg'

    print(f"\nLoading image: {image_path}")
    img = Image.open(image_path).convert('RGB')

    # Resize –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    max_size = 2048
    orig_size = img.size
    if max(img.size) > max_size:
        scale = max_size / max(img.size)
        new_size = (int(img.width * scale), int(img.height * scale))
        img = img.resize(new_size, Image.LANCZOS)
        print(f"Resized from {orig_size} to {img.size}")

    scale_factor = orig_size[0] / img.width

    img_np = np.array(img)

    # –î–µ—Ç–µ–∫—Ü–∏—è —à—Ç—Ä–∏—Ö–æ–≤–∫–∏
    wall_mask, hatching, density = detect_hatching_patterns(img_np, visualize=True)

    print("\n[5/6] Analyzing detected walls...")
    stats = analyze_walls(wall_mask, scale_factor)

    print(f"\n   Wall pixels: {stats['wall_pixels']:,}")
    print(f"   Coverage: {stats['coverage_percent']:.2f}%")
    print(f"   Segments: {stats['num_segments']}")
    print(f"   Estimated length: {stats['estimated_length_px']:,} px")
    print(f"   Avg thickness: {stats['average_thickness_px']} px")

    print("\n[6/6] Creating visualization...")

    # –°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig = plt.figure(figsize=(24, 18))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.2)

    # Row 1
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.imshow(img_np)
    ax1.set_title('Original Image', fontsize=14, fontweight='bold')
    ax1.axis('off')

    ax2 = fig.add_subplot(gs[0, 1])
    ax2.imshow(hatching, cmap='gray')
    ax2.set_title('Detected Line Patterns (Hatching)', fontsize=14, fontweight='bold')
    ax2.axis('off')

    ax3 = fig.add_subplot(gs[0, 2])
    ax3.imshow(density, cmap='hot')
    ax3.set_title('Hatching Density Map', fontsize=14, fontweight='bold')
    ax3.axis('off')
    plt.colorbar(ax3.imshow(density, cmap='hot'), ax=ax3, fraction=0.046)

    # Row 2
    ax4 = fig.add_subplot(gs[1, 0])
    ax4.imshow(wall_mask, cmap='gray')
    ax4.set_title(f'Detected Walls (Binary)\n{stats["num_segments"]} segments',
                  fontsize=14, fontweight='bold')
    ax4.axis('off')

    ax5 = fig.add_subplot(gs[1, 1])
    ax5.imshow(img_np)
    ax5.imshow(wall_mask, cmap='Reds', alpha=0.6)
    ax5.set_title(f'Walls Overlay\nCoverage: {stats["coverage_percent"]:.1f}%',
                  fontsize=14, fontweight='bold')
    ax5.axis('off')

    ax6 = fig.add_subplot(gs[1, 2])
    # –ö–æ–Ω—Ç—É—Ä—ã —Å—Ç–µ–Ω
    contour_img = img_np.copy()
    contours = extract_wall_contours(wall_mask)
    cv2.drawContours(contour_img, contours, -1, (255, 0, 0), 3)
    ax6.imshow(contour_img)
    ax6.set_title(f'Wall Contours\n{len(contours)} segments',
                  fontsize=14, fontweight='bold')
    ax6.axis('off')

    # Row 3: Comparison with DL
    ax7 = fig.add_subplot(gs[2, :])

    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç DL - —Å—Ä–∞–≤–Ω–∏–º
    try:
        import torch
        import torch.nn.functional as F
        from floortrans.models import get_model

        print("\n   Loading DL model for comparison...")
        model = get_model('hg_furukawa_original', 51)
        model.conv4_ = torch.nn.Conv2d(256, 44, bias=True, kernel_size=1)
        model.upsample = torch.nn.ConvTranspose2d(44, 44, kernel_size=4, stride=4)

        checkpoint = torch.load('model_best_val_loss_var.pkl', map_location='cpu')
        model.load_state_dict(checkpoint['model_state'])
        model.eval()

        # Predict
        img_normalized = (img_np.astype(np.float32) / 255.0 - 0.5) * 2
        img_tensor = torch.from_numpy(img_normalized).permute(2, 0, 1).unsqueeze(0)

        with torch.no_grad():
            pred = model(img_tensor)

        rooms_logits = pred[0, 21:33]
        rooms_pred = torch.argmax(rooms_logits, 0).cpu().numpy()
        dl_walls = (rooms_pred == 2).astype(np.uint8) * 255

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        comparison = np.zeros((*img_np.shape[:2], 3), dtype=np.uint8)

        # –ö—Ä–∞—Å–Ω—ã–π = —Ç–æ–ª—å–∫–æ hatching –º–µ—Ç–æ–¥
        only_hatching = (wall_mask > 0) & (dl_walls == 0)
        comparison[only_hatching] = [255, 0, 0]

        # –°–∏–Ω–∏–π = —Ç–æ–ª—å–∫–æ DL
        only_dl = (wall_mask == 0) & (dl_walls > 0)
        comparison[only_dl] = [0, 0, 255]

        # –ó–µ–ª—ë–Ω—ã–π = –æ–±–∞ –º–µ—Ç–æ–¥–∞ —Å–æ–≥–ª–∞—Å–Ω—ã
        both = (wall_mask > 0) & (dl_walls > 0)
        comparison[both] = [0, 255, 0]

        ax7.imshow(img_np)
        ax7.imshow(comparison, alpha=0.5)
        ax7.set_title('Comparison: Red=Hatching only, Blue=DL only, Green=Both agree',
                      fontsize=14, fontweight='bold', color='darkgreen')
        ax7.axis('off')

        # Statistics
        hatching_only_px = np.sum(only_hatching)
        dl_only_px = np.sum(only_dl)
        both_px = np.sum(both)
        agreement = both_px / (hatching_only_px + dl_only_px + both_px) * 100

        print(f"\n   Comparison with DL model:")
        print(f"   - Agreement: {agreement:.1f}%")
        print(f"   - Hatching only: {hatching_only_px:,} px")
        print(f"   - DL only: {dl_only_px:,} px")
        print(f"   - Both agree: {both_px:,} px")

    except Exception as e:
        print(f"\n   Could not compare with DL: {e}")
        ax7.text(0.5, 0.5, 'DL comparison not available',
                ha='center', va='center', fontsize=16,
                transform=ax7.transAxes)
        ax7.axis('off')

    output_path = 'plan_floor1_HATCHING_DETECTION.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\n‚úì Saved visualization: {output_path}")
    plt.close()

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞—Å–∫—É —Å—Ç–µ–Ω
    mask_path = 'wall_mask_auto.png'
    cv2.imwrite(mask_path, wall_mask)
    print(f"‚úì Saved wall mask: {mask_path}")

    # Export JSON
    results = {
        'method': 'Hatching pattern detection',
        'image': {
            'path': image_path,
            'original_size': list(orig_size),
            'processed_size': list(img.size),
            'scale_factor': float(scale_factor)
        },
        'statistics': stats,
        'files': {
            'visualization': output_path,
            'wall_mask': mask_path
        }
    }

    json_path = 'hatching_detection.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"‚úì Saved metadata: {json_path}")

    print(f"\n{'=' * 80}")
    print("HATCHING DETECTION COMPLETE!")
    print(f"{'=' * 80}")
    print(f"\n  üß± Detected {stats['num_segments']} wall segments")
    print(f"  üìè Total wall area: {stats['wall_area_px2']:,} px¬≤")
    print(f"  üìä Coverage: {stats['coverage_percent']:.2f}%")
    print(f"\n  üíæ Wall mask saved to: {mask_path}")
    print(f"     Use this as training data for fine-tuning!")
    print(f"\n{'=' * 80}\n")

    return wall_mask, stats

if __name__ == '__main__':
    main()
